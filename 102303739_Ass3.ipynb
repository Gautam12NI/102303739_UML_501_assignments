{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTd2bqJoh969AMNAecze/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gautam12NI/102303739_UML_501_assignments/blob/main/102303739_Ass3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSy5RsWp-RAz",
        "outputId": "21bdd712-87c3-462b-a1c9-d671d89c89a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score: 0.9179971706985147\n",
            "R2 Score: 0.9145677884802818\n",
            "R2 Score: 0.9116116385364478\n",
            "R2 Score: 0.9193091764960816\n",
            "R2 Score: 0.9243869413350316\n",
            "\n",
            "Best Beta: [1.23161736e+06 2.30225051e+05 1.63956839e+05 1.21115120e+05\n",
            " 7.83467170e+02 1.50662447e+05]\n",
            "Final R2 Score on 30% test data with best beta: 0.9147458156636434\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def least_square_beta(X, y):\n",
        "    X = np.insert(X, 0, 1, axis=1)\n",
        "    beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "    return beta\n",
        "\n",
        "df = pd.read_csv('/content/USA_Housing.csv')\n",
        "\n",
        "X = df.drop('Price', axis=1).values\n",
        "y = df['Price'].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "r2_scores = []\n",
        "betas = []\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    beta = least_square_beta(X_train, y_train)\n",
        "    betas.append(beta)\n",
        "    y_pred = np.insert(X_test, 0, 1, axis=1) @ beta\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "    print(f\"R2 Score: {r2}\")\n",
        "\n",
        "best_beta = betas[np.argmax(r2_scores)]\n",
        "print(f\"\\nBest Beta: {best_beta}\")\n",
        "\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "y_pred_final = np.insert(X_test_final, 0, 1, axis=1) @ best_beta\n",
        "final_r2 = r2_score(y_test_final, y_pred_final)\n",
        "print(f\"Final R2 Score on 30% test data with best beta: {final_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"USA_Housing.csv\")  # change filename if needed\n",
        "\n",
        "# Input features and output\n",
        "X = df.drop(\"Price\", axis=1).values\n",
        "y = df[\"Price\"].values.reshape(-1, 1)  # make y a column vector\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into Train (56%), Validation (14%), Test (30%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)   # 0.2 * 0.7 â‰ˆ 0.14\n",
        "\n",
        "# Add bias term\n",
        "def add_bias(X):\n",
        "    return np.c_[np.ones((X.shape[0], 1)), X]\n",
        "\n",
        "X_train_b = add_bias(X_train)\n",
        "X_val_b = add_bias(X_val)\n",
        "X_test_b = add_bias(X_test)\n",
        "\n",
        "# Gradient Descent function\n",
        "def gradient_descent(X, y, lr, iterations):\n",
        "    n_samples, n_features = X.shape\n",
        "    beta = np.zeros((n_features, 1))  # initialize coefficients\n",
        "    for i in range(iterations):\n",
        "        y_pred = X @ beta\n",
        "        error = y_pred - y\n",
        "        gradient = (2/n_samples) * (X.T @ error)\n",
        "        beta -= lr * gradient\n",
        "    return beta\n",
        "\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    beta = gradient_descent(X_train_b, y_train, lr, 1000)\n",
        "\n",
        "    y_val_pred = X_val_b @ beta\n",
        "    y_test_pred = X_test_b @ beta\n",
        "\n",
        "    r2_val = r2_score(y_val, y_val_pred)\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    results.append({\n",
        "        \"learning_rate\": lr,\n",
        "        \"beta\": beta,\n",
        "        \"r2_val\": r2_val,\n",
        "        \"r2_test\": r2_test\n",
        "    })\n",
        "    print(f\"Learning Rate: {lr}\")\n",
        "    print(f\"Validation R2: {r2_val:.4f}, Test R2: {r2_test:.4f}\\n\")\n",
        "\n",
        "# Find best model based on validation R2\n",
        "best_model = max(results, key=lambda x: x[\"r2_val\"])\n",
        "print(\"Best Model based on Validation R2\")\n",
        "print(\"Learning Rate:\", best_model[\"learning_rate\"])\n",
        "print(\"Validation R2:\", best_model[\"r2_val\"])\n",
        "print(\"Test R2:\", best_model[\"r2_test\"])\n",
        "print(\"Beta Coefficients:\\n\", best_model[\"beta\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZKZH0Db_uDB",
        "outputId": "d5d47719-6376-470b-ae5d-0dea69a22bdb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 0.001\n",
            "Validation R2: 0.6820, Test R2: 0.6490\n",
            "\n",
            "Learning Rate: 0.01\n",
            "Validation R2: 0.9098, Test R2: 0.9148\n",
            "\n",
            "Learning Rate: 0.1\n",
            "Validation R2: 0.9098, Test R2: 0.9148\n",
            "\n",
            "Learning Rate: 1\n",
            "Validation R2: -inf, Test R2: -inf\n",
            "\n",
            "Best Model based on Validation R2\n",
            "Learning Rate: 0.01\n",
            "Validation R2: 0.909799626728122\n",
            "Test R2: 0.9147569598865972\n",
            "Beta Coefficients:\n",
            " [[1232618.31836202]\n",
            " [ 230067.95333238]\n",
            " [ 163710.26584918]\n",
            " [ 121680.22876975]\n",
            " [   2833.37135223]\n",
            " [ 150657.57448494]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 1. Load the dataset with specified column names and replace '?' with NaN\n",
        "column_names = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "                \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
        "                \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
        "                \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
        "                \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
        "                \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data',\n",
        "                 names=column_names, na_values='?')\n",
        "\n",
        "# 2. Imputation and dropping rows\n",
        "for col in ['normalized_losses', 'horsepower', 'peak_rpm', 'price', 'bore', 'stroke']:\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    df[col] = imputer.fit_transform(df[[col]])\n",
        "df.dropna(subset=['price'], inplace=True) # Drop rows with NaN in price column\n",
        "\n",
        "# 3. Non-numeric to numeric conversion\n",
        "# (i) 'num_doors' and 'num_cylinders'\n",
        "door_map = {'two': 2, 'four': 4}\n",
        "df['num_doors'] = df['num_doors'].map(door_map).fillna(4)\n",
        "cylinder_map = {'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'eight': 8, 'twelve': 12}\n",
        "df['num_cylinders'] = df['num_cylinders'].map(cylinder_map)\n",
        "\n",
        "# (ii) Dummy encoding for 'body_style' and 'drive_wheels'\n",
        "df = pd.get_dummies(df, columns=['body_style', 'drive_wheels'], drop_first=True)\n",
        "\n",
        "# (iii) Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "for col in ['make', 'aspiration', 'engine_location', 'fuel_type']:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# (iv) 'fuel_system' encoding\n",
        "df['fuel_system'] = df['fuel_system'].apply(lambda x: 1 if 'pfi' in str(x) else 0)\n",
        "\n",
        "# (v) 'engine_type' encoding\n",
        "df['engine_type'] = df['engine_type'].apply(lambda x: 1 if 'ohc' in str(x) else 0)\n",
        "\n",
        "# 4. Divide and scale\n",
        "X = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 5. Train and test without PCA\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "linear_reg = LinearRegression()\n",
        "linear_reg.fit(X_train, y_train)\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "r2_before_pca = r2_score(y_test, y_pred)\n",
        "print(f\"R2 Score before PCA: {r2_before_pca}\")\n",
        "\n",
        "# 6. Reduce dimensionality with PCA and retrain\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
        "\n",
        "linear_reg_pca = LinearRegression()\n",
        "linear_reg_pca.fit(X_train_pca, y_train_pca)\n",
        "y_pred_pca = linear_reg_pca.predict(X_test_pca)\n",
        "r2_after_pca = r2_score(y_test_pca, y_pred_pca)\n",
        "print(f\"R2 Score after PCA: {r2_after_pca}\")\n",
        "\n",
        "if r2_after_pca > r2_before_pca:\n",
        "    print(\"\\nPerformance improved after PCA.\")\n",
        "elif r2_after_pca < r2_before_pca:\n",
        "    print(\"\\nPerformance decreased after PCA.\")\n",
        "else:\n",
        "    print(\"\\nPerformance remained the same after PCA.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP1ZUaaSBZO0",
        "outputId": "795e03a1-6391-4224-c946-ced86dadc104"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score before PCA: 0.804442243576259\n",
            "R2 Score after PCA: 0.7500675882701553\n",
            "\n",
            "Performance decreased after PCA.\n"
          ]
        }
      ]
    }
  ]
}