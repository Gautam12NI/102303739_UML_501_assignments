{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOv2jiSD/B+smFerdscgiek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gautam12NI/102303739_UML_501_assignments/blob/main/102303739_Ass4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seoHp0GVCIgW",
        "outputId": "471ee9fb-908e-4ec6-e002-bf967df2fc03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Scraping complete! Saved to books.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
        "books = []\n",
        "\n",
        "for page in range(1, 51):\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    for book in soup.find_all(\"article\", class_=\"product_pod\"):\n",
        "        title = book.h3.a[\"title\"]\n",
        "        price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
        "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "        star_rating = book.p[\"class\"][1]\n",
        "\n",
        "        books.append([title, price, availability, star_rating])\n",
        "\n",
        "df_books = pd.DataFrame(books, columns=[\"Title\", \"Price\", \"Availability\", \"Star Rating\"])\n",
        "df_books.to_csv(\"books.csv\", index=False)\n",
        "print(\" Scraping complete! Saved to books.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "759965e5",
        "outputId": "dd551474-f504-4f55-9379-f605a28cbdc1"
      },
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "url = \"https://www.imdb.com/chart/top/\"\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "driver.get(url)\n",
        "time.sleep(3)\n",
        "\n",
        "movies = []\n",
        "\n",
        "rows = driver.find_elements(By.CSS_SELECTOR, \".ipc-metadata-list-summary-item\")\n",
        "for rank, row in enumerate(rows, start=1):\n",
        "    title = row.find_element(By.CSS_SELECTOR, \"h3\").text\n",
        "    year = row.find_element(By.CSS_SELECTOR, \".cli-title-metadata-item\").text\n",
        "    rating = row.find_element(By.CSS_SELECTOR, \".ipc-rating-star\").text.split()[0]\n",
        "    movies.append([rank, title, year, rating])\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "df_movies = pd.DataFrame(movies, columns=[\"Rank\", \"Movie Title\", \"Year\", \"IMDB Rating\"])\n",
        "df_movies.to_csv(\"imdb_top250.csv\", index=False)\n",
        "print(\" IMDB Top 250 saved to imdb_top250.csv\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " IMDB Top 250 saved to imdb_top250.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.timeanddate.com/weather/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "cities = []\n",
        "for row in soup.select(\"table tbody tr\"):\n",
        "    try:\n",
        "        city = row.find(\"a\").text\n",
        "        temp = row.find(\"td\", class_=\"rbi\").text\n",
        "        condition = row.find_all(\"td\")[2].text\n",
        "        cities.append([city, temp, condition])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "df_weather = pd.DataFrame(cities, columns=[\"City\", \"Temperature\", \"Condition\"])\n",
        "df_weather.to_csv(\"weather.csv\", index=False)\n",
        "print(\" Weather data saved to weather.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGBvMOv6DaTl",
        "outputId": "15aa783f-2465-42c0-a967-df2117a5a733"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Weather data saved to weather.csv\n"
          ]
        }
      ]
    }
  ]
}